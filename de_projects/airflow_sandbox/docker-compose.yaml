version: "3.9"

x-airflow-common: &airflow-common
  build: .
  restart: always

  environment:
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"

    AIRFLOW_CONN_SPARK_DEFAULT: spark://spark-master:7077
    AIRFLOW_CONN_SPARK_URI: spark://spark-master:7077

    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow

    AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    
    # StatsD metrics for monitoring
    AIRFLOW__METRICS__STATSD_ON: "true"
    AIRFLOW__METRICS__STATSD_HOST: "statsd-exporter"
    AIRFLOW__METRICS__STATSD_PORT: "9125"
    AIRFLOW__METRICS__STATSD_PREFIX: "airflow"
    
    SPARK_HOME: /opt/spark
    PATH: /home/airflow/.local/bin:/opt/spark/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
    _AIRFLOW_WWW_USER_USERNAME: admin
    _AIRFLOW_WWW_USER_PASSWORD: admin
    _AIRFLOW_WWW_USER_EMAIL: admin@example.com
    _AIRFLOW_WWW_USER_FIRSTNAME: Admin
    _AIRFLOW_WWW_USER_LASTNAME: User
    _AIRFLOW_WWW_USER_ROLE: Admin

  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./config:/opt/airflow/config
    - ./spark:/opt/spark-jobs
    - /var/run/docker.sock:/var/run/docker.sock

  depends_on:
    postgres:
      condition: service_healthy
    redis:
      condition: service_healthy

services:
  # -------------------- DB --------------------
  postgres:
    image: postgres:15
    container_name: airflow_postgres
    networks:
      - airflow-spark

    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow

    volumes:
      - postgres-data:/var/lib/postgresql/data

    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
    
    ports:
      - "5432:5432"

    restart: always

  # -------------------- Redis --------------------
  redis:
    image: redis:7
    container_name: airflow_redis
    networks:
      - airflow-spark

    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 10

    restart: always

  # -------------------- INIT --------------------
  airflow-init:
    <<: *airflow-common
    container_name: airflow_init
    networks:
      - airflow-spark

    entrypoint: /bin/bash

    command: -c "until airflow db check; do sleep 5; done; airflow db migrate; airflow users create -u admin -p admin -f Admin -l User -r Admin -e admin@example.com || true"

    restart: "no"

  # -------------------- WEBSERVER --------------------
  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_webserver

    command: webserver

    ports:
      - "8080:8080"

    networks:
      - airflow-spark

    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    
    restart: always
    depends_on:
            - postgres

  # -------------------- SCHEDULER --------------------
  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    networks:
      - airflow-spark

    command: scheduler

  # -------------------- WORKER --------------------
  airflow-worker:
    <<: *airflow-common
    container_name: airflow_worker
    networks:
      - airflow-spark

    command: celery worker

    # -------------------- SPARK MASTER --------------------
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark_master
    hostname: spark-master
    networks:
      - airflow-spark

    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master

    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no

    ports:
      - "7077:7077"
      - "8081:8080"

    restart: always

  # -------------------- SPARK WORKER --------------------
  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark_worker
    networks:
      - airflow-spark

    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no

    depends_on:
      - spark-master

    restart: always

  # ==================== MONITORING STACK ====================
  
  # -------------------- PROMETHEUS --------------------
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: prometheus
    hostname: prometheus
    networks:
      - airflow-spark
    
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    
    volumes:
      - ./config/prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    
    ports:
      - "9090:9090"
    
    restart: unless-stopped

  # -------------------- GRAFANA --------------------
  grafana:
    image: grafana/grafana:10.0.3
    container_name: grafana
    hostname: grafana
    networks:
      - airflow-spark
    
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_INSTALL_PLUGINS=
    
    volumes:
      - ./config/grafana/provisioning:/etc/grafana/provisioning
      - ./config/grafana/dashboards:/etc/grafana/dashboards
      - grafana-data:/var/lib/grafana
    
    ports:
      - "3000:3000"
    
    depends_on:
      - prometheus
      - loki
    
    restart: unless-stopped

  # -------------------- LOKI --------------------
  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    hostname: loki
    networks:
      - airflow-spark
    
    command: -config.file=/etc/loki/loki-config.yml
    
    volumes:
      - ./config/loki:/etc/loki
      - loki-data:/loki
    
    ports:
      - "3100:3100"
    
    restart: unless-stopped

  # -------------------- PROMTAIL --------------------
  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    hostname: promtail
    networks:
      - airflow-spark
    
    command: -config.file=/etc/promtail/promtail-config.yml
    
    volumes:
      - ./config/promtail:/etc/promtail
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    
    depends_on:
      - loki
    
    restart: unless-stopped

  # -------------------- CADVISOR --------------------
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    container_name: cadvisor
    hostname: cadvisor
    networks:
      - airflow-spark
    
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    
    ports:
      - "8082:8080"
    
    restart: unless-stopped
    
    privileged: true

  # -------------------- POSTGRES EXPORTER --------------------
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.13.2
    container_name: postgres_exporter
    networks:
      - airflow-spark
    
    environment:
      DATA_SOURCE_NAME: "postgresql://airflow:airflow@postgres:5432/airflow?sslmode=disable"
    
    ports:
      - "9187:9187"
    
    depends_on:
      - postgres
    
    restart: unless-stopped

  # -------------------- REDIS EXPORTER --------------------
  redis-exporter:
    image: oliver006/redis_exporter:v1.52.0-alpine
    container_name: redis_exporter
    networks:
      - airflow-spark
    
    environment:
      REDIS_ADDR: "redis:6379"
    
    ports:
      - "9121:9121"
    
    depends_on:
      - redis
    
    restart: unless-stopped

  # -------------------- STATSD EXPORTER --------------------
  statsd-exporter:
    image: prom/statsd-exporter:v0.26.0
    container_name: statsd_exporter
    networks:
      - airflow-spark
    
    ports:
      - "9102:9102"
      - "9125:9125/udp"
    
    restart: unless-stopped

networks:
  airflow-spark:
    driver: bridge

volumes:
  postgres-data:
  prometheus-data:
  grafana-data:
  loki-data:
