version: '3.8'

x-airflow-common: &airflow-common
  build: ./docker/airflow
  user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
  env_file: .env
  environment:
    # --- AIRFLOW 3 REQUIRED ---
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
    AIRFLOW_CONN_SPARK_DEFAULT: "spark://spark-master:7077"
  volumes:
    - ./docker/airflow/dags:/opt/airflow/dags
    - ./docker/airflow/logs:/opt/airflow/logs
    - ./docker/airflow/plugins:/opt/airflow/plugins
    - ./dbt:/opt/dbt
    - ./great_expectations:/opt/great_expectations
    - ./scripts:/opt/scripts
    - ./docker/spark/jobs:/opt/spark/jobs
    - ./data:/opt/spark/data
  depends_on:
    - spark-master
    - postgres
    - minio

services:
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8081:8080" # Spark Master Web UI
      - "7077:7077" # Spark Master communication
    environment:
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_MASTER_PORT=7077
      - SPARK_NO_DAEMONIZE=true
      - SPARK_HOME=/opt/spark
    entrypoint: ""
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master"

  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
      - SPARK_NO_DAEMONIZE=true
      - SPARK_HOME=/opt/spark
    entrypoint: ""
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
  postgres:
    image: postgres:13
    container_name: postgres
    restart: always
    ports:
      - "5432:5432"
    env_file: .env
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    container_name: minio
    restart: always
    ports:
      - "9000:9000"
      - "9001:9001"
    env_file: .env
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-init:
    <<: *airflow-common
    container_name: airflow_init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        set -e
        echo "Running Airflow DB migrations..."
        airflow db migrate
        echo "DB migration complete."
    restart: "no"

  airflow-dag-processor:
    <<: *airflow-common
    container_name: airflow_dag_processor
    command: airflow dag-processor
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    restart: always  

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_webserver
    command: airflow api-server
    ports:
      - "8080:8080"
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    command: airflow scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $$(hostname)"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: always

  postgres_exporter:
    image: wrouesnel/postgres_exporter
    container_name: postgres_exporter
    restart: always
    environment:
      DATA_SOURCE_NAME: "postgresql://user:password@postgres:5432/postgres?sslmode=disable"
    ports:
      - "9187:9187"
    depends_on:
      - postgres
  prometheus:
    image: prom/prometheus:v2.37.0
    container_name: prometheus
    restart: always
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command: --config.file=/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:8.5.2
    container_name: grafana
    restart: always
    ports:
      - "3000:3000"
    env_file: .env
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - grafana_data:/var/lib/grafana

  loki:
    image: grafana/loki:2.6.1
    container_name: loki
    restart: always
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml

  promtail:
    image: grafana/promtail:2.6.1
    container_name: promtail
    restart: always
    volumes:
      - /var/log:/var/log
      - /var/lib/docker/containers:/var/lib/docker/containers
      - ./monitoring/loki/promtail-config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml

volumes:
  postgres_data:
  minio_data:
  grafana_data:
