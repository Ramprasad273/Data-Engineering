# Data Engineering Projects

This repository is a collection of hands-on data engineering projects, each designed to demonstrate different technologies and concepts in the field.

## Projects

### 1. Airflow Sandbox with Spark

This project provides a Dockerized environment for running data pipelines with Apache Airflow and Apache Spark. It's a great starting point for developing and testing ETL/ELT workflows.

-   **Technologies**: Docker, Docker Compose, Apache Airflow, Apache Spark, PostgreSQL, Redis.
-   **Location**: `de_projects/airflow_sandbox`
-   **[>> Go to the Airflow Sandbox Project README for full details](./de_projects/airflow_sandbox/README.md)**

### 2. Kafka 101: Producer and Consumer

A fundamental introduction to Apache Kafka, this project demonstrates a simple producer-consumer setup using Python.

-   **Technologies**: Python, Apache Kafka.
-   **Location**: `de_projects/Kakfa_projects/Kafka_101`
-   **[>> Go to the Kafka 101 Project README for full details](./de_projects/Kakfa_projects/Kafka_101/Readme.md)**

## Getting Started

To get started with any of the projects, please refer to the detailed `README.md` file located in each project's directory. The prerequisites and setup instructions are specific to each project.

## Contributing

Contributions are welcome! If you have a data engineering project or an improvement you'd like to share, please feel free to create a pull request.